{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MPTI2_ex5_3_KNNvsRandFor.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNMKzncT2+vQmjK9peXYACk"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yHH0YJupesos"},"source":["#Д/з по метрическим методам\n","\n","В этом задании будет использоваться датасет digits из sklearn.datasets. Оставьте последние 25% объектов для контроля качества, разделив X и y на X_train, y_train и X_test, y_test.\n","\n","Целью задания будет реализовать самый простой метрический классификатор — метод ближайшего соседа, а также сравнить качество работы реализованного вами 1NN с RandomForestClassifier из sklearn на 1000 деревьях."]},{"cell_type":"code","metadata":{"id":"Een95SDveeYB","executionInfo":{"status":"ok","timestamp":1603585174611,"user_tz":-180,"elapsed":1081,"user":{"displayName":"николай курбатов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57uCgi07Vm90L5Vwv1GUpphfPe9PXcaRkKV6c=s64","userId":"00086192279349692157"}},"outputId":"47e53c00-159a-45ce-9d71-defa068e3eba","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_digits\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","%pylab inline"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Ie69nyLs5tE","executionInfo":{"status":"ok","timestamp":1603584765966,"user_tz":-180,"elapsed":956,"user":{"displayName":"николай курбатов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57uCgi07Vm90L5Vwv1GUpphfPe9PXcaRkKV6c=s64","userId":"00086192279349692157"}}},"source":["data = load_digits()\n","X, y = data.data, data.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.25)"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y7YBfX6ofRam"},"source":["##Задание 1\n","\n","Реализуйте самостоятельно метод одного ближайшего соседа с евклидовой метрикой для задачи классификации. Можно не извлекать корень из суммы квадратов отклонений, т.к. корень — монотонное преобразование и не влияет на результат работы алгоритма.\n","\n","Никакой дополнительной работы с признаками в этом задании делать не нужно — мы еще успеем этим заняться в других курсах. Ваша реализация может быть устроена следующим образом: можно для каждого классифицируемого объекта составлять список пар (расстояние до точки из обучающей выборки, метка класса в этой точке), затем сортировать этот список (по умолчанию сортировка будет сначала по первому элементу пары, затем по второму), а затем брать первый элемент (с наименьшим расстоянием).\n","\n","Сортировка массива длиной N требует порядка N log N сравнений (строже говоря, она работает за O(N log N)). Подумайте, как можно легко улучшить получившееся время работы. Кроме простого способа найти ближайший объект всего за N сравнений, можно попробовать придумать, как разбить пространство признаков на части и сделать структуру данных, которая позволит быстро искать соседей каждой точки. За выбор метода поиска ближайших соседей в KNeighborsClassifier из sklearn отвечает параметр algorithm — если у вас уже есть некоторый бэкграунд в алгоритмах и структурах данных, вам может быть интересно познакомиться со структурами данных ball tree и kd tree.\n","\n","Доля ошибок, допускаемых 1NN на тестовой выборке, — ответ в задании 1."]},{"cell_type":"code","metadata":{"id":"Q57yFuOPfVNf","executionInfo":{"status":"ok","timestamp":1603584808280,"user_tz":-180,"elapsed":1251,"user":{"displayName":"николай курбатов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57uCgi07Vm90L5Vwv1GUpphfPe9PXcaRkKV6c=s64","userId":"00086192279349692157"}}},"source":["def dist(v1, v2):\n","    return sum((v1 - v2)**2)\n","\n","# Main classification procedure\n","def clf_1NN(X_train, X_test, y_train):\n","  test_labels = [] \n","\n","  for test_point in X_test:\n","    # Claculate distances between test point and all of the train points\n","    test_dist = [dist(test_point, x_tr) for x_tr in X_train]\n","    # Find nearest point in train_set\n","    near_point_ind = test_dist.index( min(test_dist) )\n","    test_labels.append( y_train[near_point_ind] )\n","\n","  return np.asarray(test_labels)\n","\n","def error_score(y_pred, y_test):\n","  err = np.sum(y_pred != y_test)\n","  return float(err) / float(len(y_test))"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"wnHrwiLwAb56","executionInfo":{"status":"ok","timestamp":1603584815199,"user_tz":-180,"elapsed":5498,"user":{"displayName":"николай курбатов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57uCgi07Vm90L5Vwv1GUpphfPe9PXcaRkKV6c=s64","userId":"00086192279349692157"}},"outputId":"4cc0f5f3-ec6b-460a-99db-1ca134c7676c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y_pred = clf_1NN(X_train, X_test, y_train)\n","error_score(y_pred, y_test)"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.03777777777777778"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"kNozAFaDBLwu","executionInfo":{"status":"ok","timestamp":1603584819711,"user_tz":-180,"elapsed":1419,"user":{"displayName":"николай курбатов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57uCgi07Vm90L5Vwv1GUpphfPe9PXcaRkKV6c=s64","userId":"00086192279349692157"}}},"source":["with open('ans_1.txt', 'w') as fout:\n","  fout.write(str(error_score(y_pred, y_test)))"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6L6sdfKTqppv"},"source":["##Задание 2\n","\n","Теперь обучите на обучающей выборке RandomForestClassifier(n_estimators=1000) из sklearn. Сделайте прогнозы на тестовой выборке и оцените долю ошибок классификации на ней. Эта доля — ответ в задании 2. Обратите внимание на то, как соотносится качество работы случайного леса с качеством работы, пожалуй, одного из самых простых методов — 1NN. Такое различие — особенность данного датасета, но нужно всегда помнить, что такая ситуация тоже может иметь место, и не забывать про простые методы.\n","\n","Как отправить\n","Когда работа будет готова, вы можете загрузить файлы для каждой части задания на вкладке 'Мои работы'."]},{"cell_type":"code","metadata":{"id":"6CZSjI_XqsXf","executionInfo":{"status":"ok","timestamp":1603585260672,"user_tz":-180,"elapsed":4869,"user":{"displayName":"николай курбатов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57uCgi07Vm90L5Vwv1GUpphfPe9PXcaRkKV6c=s64","userId":"00086192279349692157"}}},"source":["clf = RandomForestClassifier(n_estimators=1000)\n","clf.fit(X_train, y_train)\n","\n","y_rand_pred = clf.predict(X_test)\n","score_rf = 1 - accuracy_score(y_test, y_rand_pred)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"FUo5gT_wIHyF","executionInfo":{"status":"ok","timestamp":1603585268265,"user_tz":-180,"elapsed":1416,"user":{"displayName":"николай курбатов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57uCgi07Vm90L5Vwv1GUpphfPe9PXcaRkKV6c=s64","userId":"00086192279349692157"}}},"source":["with open('ans_2.txt', 'w') as fout:\n","  fout.write(str(score_rf))"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHeYTq8vIVNQ"},"source":[""],"execution_count":null,"outputs":[]}]}